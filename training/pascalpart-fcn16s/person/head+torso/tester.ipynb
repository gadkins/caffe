{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import caffe\n",
    "import score\n",
    "import tools\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fast_hist(a, b, n):\n",
    "    k = (a >= 0) & (a < n) # a boolean index array \n",
    "    # Select only positive samples less than # of classes (i.e. values 0 - 10 for 11-class fcn)\n",
    "    return np.bincount(n * a[k].astype(int) + b[k], minlength=n**2).reshape(n, n)\n",
    "\n",
    "def compute_hist(net, save_dir, dataset, layer='score', gt='label'):\n",
    "    # N.B. channels refers to num_output pages for FCN\n",
    "    n_cl = net.blobs[layer].channels\n",
    "    if save_dir:    \n",
    "    \tos.mkdir(save_dir)\n",
    "    hist = np.zeros((n_cl, n_cl))\n",
    "    loss = 0\n",
    "    for idx in dataset:\n",
    "        net.forward()\n",
    "        hist += fast_hist(net.blobs[gt].data[0, 0].flatten(),\n",
    "                                net.blobs[layer].data[0].argmax(0).flatten(),\n",
    "                                n_cl)\n",
    "\n",
    "        if save_dir:\n",
    "            im = Image.fromarray(net.blobs[layer].data[0].argmax(0).astype(np.uint8), mode='P')\n",
    "            im.save(os.path.join(save_dir, idx + '.png'))\n",
    "        # compute the loss as well\n",
    "        loss += net.blobs['loss'].data.flat[0]\n",
    "    return hist, loss / len(dataset)\n",
    "\n",
    "def seg_tests(solver, save_format, dataset, layer='score', gt='label'):\n",
    "    print '>>>', datetime.now(), 'Begin seg tests'\n",
    "    solver.test_nets[0].share_with(solver.net)\n",
    "    do_seg_tests(solver.test_nets[0], solver.iter, save_format, dataset, layer, gt)\n",
    "\n",
    "def do_seg_tests(net, iter, save_format, dataset, layer='score', gt='label'):\n",
    "    n_cl = net.blobs[layer].channels\n",
    "    if save_format:\n",
    "        save_format = save_format.format(iter)\n",
    "    hist, loss = compute_hist(net, save_format, dataset, layer, gt)\n",
    "    # mean loss\n",
    "    print '>>>', datetime.now(), 'Iteration', iter, 'loss', loss\n",
    "    # overall accuracy\n",
    "    acc = np.diag(hist).sum() / hist.sum()\n",
    "    print '>>>', datetime.now(), 'Iteration', iter, 'overall accuracy', acc\n",
    "    # per-class accuracy\n",
    "    acc = np.diag(hist) / hist.sum(1)\n",
    "    print '>>>', datetime.now(), 'Iteration', iter, 'mean accuracy', np.nanmean(acc)\n",
    "    # per-class IU\n",
    "    iu = np.diag(hist) / (hist.sum(1) + hist.sum(0) - np.diag(hist))\n",
    "    print '>>>', datetime.now(), 'Iteration', iter, 'mean IU', np.nanmean(iu)\n",
    "    freq = hist.sum(1) / hist.sum()\n",
    "    print '>>>', datetime.now(), 'Iteration', iter, 'fwavacc', \\\n",
    "            (freq[freq > 0] * iu[freq > 0]).sum()\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapse: 4s\n"
     ]
    }
   ],
   "source": [
    "caffe.set_device(0)\n",
    "caffe.set_mode_cpu()\n",
    "\n",
    "caffe_root = '/home/cv/hdl/caffe'\n",
    "part = 'head'\n",
    "models = '{}/models'.format(caffe_root)\n",
    "\n",
    "# load image, switch to BGR, subtract mean, and make dims C x H x W for Caffe\n",
    "im = Image.open('/home/cv/grayson/shelby_medium.jpg')\n",
    "in_ = np.array(im, dtype=np.float32)\n",
    "in_ = in_[:,:,::-1]\n",
    "in_ -= np.array((104.00698793,116.66876762,122.67891434))\n",
    "in_ = in_.transpose((2,0,1))\n",
    "\n",
    "# load net\n",
    "# net = caffe.Net('model/deploy.prototxt',\n",
    "#                 '{}/pascalpart-fcn32s/person/head/old_snapshots/train_iter_176000.caffemodel'.format(models), \n",
    "#                 caffe.TEST)\n",
    "net = caffe.Net('model/deploy.prototxt',\n",
    "                'snapshot/train_iter_96000.caffemodel'.format(models), \n",
    "                caffe.TEST)\n",
    "\n",
    "# shape for input (data blob is N x C x H x W), set data\n",
    "net.blobs['data'].reshape(1, *in_.shape)\n",
    "net.blobs['data'].data[...] = in_\n",
    "\n",
    "# must do forward pass or else blobs and deconv params will be all zeroes\n",
    "net.forward()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8935.6787"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just the loss\n",
    "net.blobs['loss'].data.flat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# solver = caffe.SGDSolver('model/solver.prototxt')\n",
    "# solver.test_nets[0].share_with(solver.net)\n",
    "# val = np.loadtxt('{}/data/pascal/VOC/VOC2010/ImageSets/person/{}_val.txt'.format(caffe_root, part), dtype=str)\n",
    "\n",
    "# hist, loss = do_seg_tests(solver.test_nets[0], solver.iter, False, val, 'score', 'label')\n",
    "\n",
    "# hist += fast_hist(net.blobs['label'].data[0, 0].flatten(),\n",
    "#                                 net.blobs['score'].data[0].argmax(0).flatten(),\n",
    "#                                 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.imshow(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.blobs['score'].channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print np.shape(net.blobs['label'].data[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print np.shape(net.blobs['score'].data[0].argmax(0))\n",
    "# print np.unique(net.blobs['score'].data[0].argmax(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#solver = caffe.SGDSolver('solver.prototxt')\n",
    "#val = np.loadtxt('/home/cv/hdl/caffe/data/pascal/VOC/VOC2010/ImageSets/person/head_val.txt', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#hist, loss = score.compute_hist(solver.test_nets[0], 'segmentation_results', val, layer='score', gt='label' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.blobs['score'].channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# blobs\n",
    "# [(k, v.data.shape) for k, v in net.blobs.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "# [(k, v[0].data.shape) for k, v in net.params.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# conv layer weights (edge_detectors)\n",
    "# print net.params['fc6'][0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# deconv layer weights\n",
    "# print net.params['conv1_1'][0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data blob\n",
    "# print net.blobs['data'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# conv1_1 blob\n",
    "# print net.blobs['conv1_1'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pool1 blob\n",
    "# print net.blobs['pool1'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# upscore blob\n",
    "# print net.blobs['upscore'].data.shape\n",
    "# print net.blobs['upscore'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 375, 500)\n",
      "Image size: (375, 500)\n",
      "Detected object classes: [0 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVYAAAEKCAYAAABJ430PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f914b27de50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "higher_level_filter = net.params['fc7'][0].data         # weights\n",
    "# Recall: blob dimensions are N x C x H x W\n",
    "print net.blobs['score'].data[0].shape\n",
    "out = net.blobs['score'].data[0].argmax(axis=0)\n",
    "fig = plt.figure()\n",
    "plt.axis('off')\n",
    "plt.title('head_inference')\n",
    "imgplot = plt.imshow(out)\n",
    "print 'Image size:', out.shape\n",
    "print 'Detected object classes:', np.unique(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig.savefig('torso_inference.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
